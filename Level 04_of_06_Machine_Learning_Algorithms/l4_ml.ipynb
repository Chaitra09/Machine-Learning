{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "df =pd.read_csv(\"C:/Users/ramreddymyla/Google Drive/01 DS ML DL NLP and AI With Python Lab Copy/02 Lab Data/Python/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.species.replace(to_replace=['setosa', 'versicolor', 'virginica'],value=[0,1,2]).values\n",
    "type(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split(train (70%),test(30%))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_square_and_cube(arg1):\n",
    "    return arg1 **2 ,arg1 **3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,s = fun_square_and_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,\n",
    "                                               test_size =0.3,\n",
    "                                               random_state=32,\n",
    "                                               shuffle =True,\n",
    "                                               stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([50, 50, 50], dtype=int64))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([35, 35, 35], dtype=int64))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([15, 15, 15], dtype=int64))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit the model\n",
    "* training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train) # 105 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.6, 0.4],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0.4, 0.6],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.8, 0.2],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 0, 0,\n",
       "       0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 0, 0,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 2.3, 3.3, 1. ],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [6.7, 2.5, 5.8, 1.8]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 0, 0,\n",
       "       0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 0, 0,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 0, 0,\n",
       "       0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 0, 0,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test == y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "44/45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## our own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minkowski'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmetric_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Classifier implementing the k-nearest neighbors vote.\n",
       "\n",
       "Read more in the :ref:`User Guide <classification>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_neighbors : int, optional (default = 5)\n",
       "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
       "\n",
       "weights : str or callable, optional (default = 'uniform')\n",
       "    weight function used in prediction.  Possible values:\n",
       "\n",
       "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
       "      are weighted equally.\n",
       "    - 'distance' : weight points by the inverse of their distance.\n",
       "      in this case, closer neighbors of a query point will have a\n",
       "      greater influence than neighbors which are further away.\n",
       "    - [callable] : a user-defined function which accepts an\n",
       "      array of distances, and returns an array of the same shape\n",
       "      containing the weights.\n",
       "\n",
       "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
       "    Algorithm used to compute the nearest neighbors:\n",
       "\n",
       "    - 'ball_tree' will use :class:`BallTree`\n",
       "    - 'kd_tree' will use :class:`KDTree`\n",
       "    - 'brute' will use a brute-force search.\n",
       "    - 'auto' will attempt to decide the most appropriate algorithm\n",
       "      based on the values passed to :meth:`fit` method.\n",
       "\n",
       "    Note: fitting on sparse input will override the setting of\n",
       "    this parameter, using brute force.\n",
       "\n",
       "leaf_size : int, optional (default = 30)\n",
       "    Leaf size passed to BallTree or KDTree.  This can affect the\n",
       "    speed of the construction and query, as well as the memory\n",
       "    required to store the tree.  The optimal value depends on the\n",
       "    nature of the problem.\n",
       "\n",
       "p : integer, optional (default = 2)\n",
       "    Power parameter for the Minkowski metric. When p = 1, this is\n",
       "    equivalent to using manhattan_distance (l1), and euclidean_distance\n",
       "    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
       "\n",
       "metric : string or callable, default 'minkowski'\n",
       "    the distance metric to use for the tree.  The default metric is\n",
       "    minkowski, and with p=2 is equivalent to the standard Euclidean\n",
       "    metric. See the documentation of the DistanceMetric class for a\n",
       "    list of available metrics.\n",
       "\n",
       "metric_params : dict, optional (default = None)\n",
       "    Additional keyword arguments for the metric function.\n",
       "\n",
       "n_jobs : int or None, optional (default=None)\n",
       "    The number of parallel jobs to run for neighbors search.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "    Doesn't affect :meth:`fit` method.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> X = [[0], [1], [2], [3]]\n",
       ">>> y = [0, 0, 1, 1]\n",
       ">>> from sklearn.neighbors import KNeighborsClassifier\n",
       ">>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
       ">>> neigh.fit(X, y) # doctest: +ELLIPSIS\n",
       "KNeighborsClassifier(...)\n",
       ">>> print(neigh.predict([[1.1]]))\n",
       "[0]\n",
       ">>> print(neigh.predict_proba([[0.9]]))\n",
       "[[0.66666667 0.33333333]]\n",
       "\n",
       "See also\n",
       "--------\n",
       "RadiusNeighborsClassifier\n",
       "KNeighborsRegressor\n",
       "RadiusNeighborsRegressor\n",
       "NearestNeighbors\n",
       "\n",
       "Notes\n",
       "-----\n",
       "See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
       "for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
       "\n",
       ".. warning::\n",
       "\n",
       "   Regarding the Nearest Neighbors algorithms, if it is found that two\n",
       "   neighbors, neighbor `k+1` and `k`, have identical distances\n",
       "   but different labels, the results will depend on the ordering of the\n",
       "   training data.\n",
       "\n",
       "https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\ramreddymyla\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\neighbors\\classification.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (2, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (2, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (2, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (2, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (2, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (2, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (2, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (2, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (2, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (2, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (2, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (3, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (3, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (3, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (3, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (3, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (3, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (3, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (3, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (3, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (3, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (3, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (3, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (4, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (4, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (4, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (4, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (4, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (4, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (4, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (4, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (4, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (4, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (4, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (4, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (5, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (5, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (5, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (5, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (5, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (5, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (5, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (5, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (5, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (5, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (5, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (5, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (6, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (6, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (6, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (6, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (6, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (6, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (6, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (6, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (6, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (6, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (6, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (6, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (7, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (7, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (7, 'ball_tree', 2, 'uniform', 0.9555555555555556),\n",
       " (7, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (7, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (7, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (7, 'kd_tree', 2, 'uniform', 0.9555555555555556),\n",
       " (7, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (7, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (7, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (7, 'brute', 2, 'uniform', 0.9555555555555556),\n",
       " (7, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (8, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (8, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (8, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (8, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (8, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (8, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (8, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (8, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (8, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (8, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (8, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (8, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (9, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (9, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (9, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (9, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (9, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (9, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (9, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (9, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (9, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (9, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (9, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (9, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (10, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (10, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (10, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (10, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (10, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (10, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (10, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (10, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (10, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (10, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (10, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (10, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (11, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (11, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (11, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (11, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (11, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (11, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (11, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (11, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (11, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (11, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (11, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (11, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (12, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (12, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (12, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (12, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (12, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (12, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (12, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (12, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (12, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (12, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (12, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (12, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (13, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (13, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (13, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (13, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (13, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (13, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (13, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (13, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (13, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (13, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (13, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (13, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (14, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (14, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (14, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (14, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (14, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (14, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (14, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (14, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (14, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (14, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (14, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (14, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (15, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (15, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (15, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (15, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (15, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (15, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (15, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (15, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (15, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (15, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (15, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (15, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (16, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (16, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (16, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (16, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (16, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (16, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (16, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (16, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (16, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (16, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (16, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (16, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (17, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (17, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (17, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (17, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (17, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (17, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (17, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (17, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (17, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (17, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (17, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (17, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (18, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (18, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (18, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (18, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (18, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (18, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (18, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (18, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (18, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (18, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (18, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (18, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (19, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (19, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (19, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (19, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (19, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (19, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (19, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (19, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (19, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (19, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (19, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (19, 'brute', 2, 'distance', 0.9777777777777777),\n",
       " (20, 'ball_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (20, 'ball_tree', 1, 'distance', 0.9777777777777777),\n",
       " (20, 'ball_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (20, 'ball_tree', 2, 'distance', 0.9777777777777777),\n",
       " (20, 'kd_tree', 1, 'uniform', 0.9777777777777777),\n",
       " (20, 'kd_tree', 1, 'distance', 0.9777777777777777),\n",
       " (20, 'kd_tree', 2, 'uniform', 0.9777777777777777),\n",
       " (20, 'kd_tree', 2, 'distance', 0.9777777777777777),\n",
       " (20, 'brute', 1, 'uniform', 0.9777777777777777),\n",
       " (20, 'brute', 1, 'distance', 0.9777777777777777),\n",
       " (20, 'brute', 2, 'uniform', 0.9777777777777777),\n",
       " (20, 'brute', 2, 'distance', 0.9777777777777777)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=[]\n",
    "for i in range(2,21):\n",
    "    for alg in  ['ball_tree', 'kd_tree', 'brute']:\n",
    "        for p in [1,2]:\n",
    "            for w in [\"uniform\",\"distance\"]:\n",
    "                model=KNeighborsClassifier(n_neighbors=i,algorithm=alg,p=p,weights=w)\n",
    "                model.fit(X_train,y_train) # 105 samples\n",
    "                y_test_pred=model.predict(X_test)\n",
    "                acc.append((i,alg,p,w,accuracy_score(y_test,y_test_pred)))\n",
    "acc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minkowski'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmetric_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Classifier implementing the k-nearest neighbors vote.\n",
       "\n",
       "Read more in the :ref:`User Guide <classification>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_neighbors : int, optional (default = 5)\n",
       "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
       "\n",
       "weights : str or callable, optional (default = 'uniform')\n",
       "    weight function used in prediction.  Possible values:\n",
       "\n",
       "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
       "      are weighted equally.\n",
       "    - 'distance' : weight points by the inverse of their distance.\n",
       "      in this case, closer neighbors of a query point will have a\n",
       "      greater influence than neighbors which are further away.\n",
       "    - [callable] : a user-defined function which accepts an\n",
       "      array of distances, and returns an array of the same shape\n",
       "      containing the weights.\n",
       "\n",
       "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
       "    Algorithm used to compute the nearest neighbors:\n",
       "\n",
       "    - 'ball_tree' will use :class:`BallTree`\n",
       "    - 'kd_tree' will use :class:`KDTree`\n",
       "    - 'brute' will use a brute-force search.\n",
       "    - 'auto' will attempt to decide the most appropriate algorithm\n",
       "      based on the values passed to :meth:`fit` method.\n",
       "\n",
       "    Note: fitting on sparse input will override the setting of\n",
       "    this parameter, using brute force.\n",
       "\n",
       "leaf_size : int, optional (default = 30)\n",
       "    Leaf size passed to BallTree or KDTree.  This can affect the\n",
       "    speed of the construction and query, as well as the memory\n",
       "    required to store the tree.  The optimal value depends on the\n",
       "    nature of the problem.\n",
       "\n",
       "p : integer, optional (default = 2)\n",
       "    Power parameter for the Minkowski metric. When p = 1, this is\n",
       "    equivalent to using manhattan_distance (l1), and euclidean_distance\n",
       "    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
       "\n",
       "metric : string or callable, default 'minkowski'\n",
       "    the distance metric to use for the tree.  The default metric is\n",
       "    minkowski, and with p=2 is equivalent to the standard Euclidean\n",
       "    metric. See the documentation of the DistanceMetric class for a\n",
       "    list of available metrics.\n",
       "\n",
       "metric_params : dict, optional (default = None)\n",
       "    Additional keyword arguments for the metric function.\n",
       "\n",
       "n_jobs : int or None, optional (default=None)\n",
       "    The number of parallel jobs to run for neighbors search.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "    Doesn't affect :meth:`fit` method.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> X = [[0], [1], [2], [3]]\n",
       ">>> y = [0, 0, 1, 1]\n",
       ">>> from sklearn.neighbors import KNeighborsClassifier\n",
       ">>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
       ">>> neigh.fit(X, y) # doctest: +ELLIPSIS\n",
       "KNeighborsClassifier(...)\n",
       ">>> print(neigh.predict([[1.1]]))\n",
       "[0]\n",
       ">>> print(neigh.predict_proba([[0.9]]))\n",
       "[[0.66666667 0.33333333]]\n",
       "\n",
       "See also\n",
       "--------\n",
       "RadiusNeighborsClassifier\n",
       "KNeighborsRegressor\n",
       "RadiusNeighborsRegressor\n",
       "NearestNeighbors\n",
       "\n",
       "Notes\n",
       "-----\n",
       "See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
       "for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
       "\n",
       ".. warning::\n",
       "\n",
       "   Regarding the Nearest Neighbors algorithms, if it is found that two\n",
       "   neighbors, neighbor `k+1` and `k`, have identical distances\n",
       "   but different labels, the results will depend on the ordering of the\n",
       "   training data.\n",
       "\n",
       "https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\ramreddymyla\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\neighbors\\classification.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2*n_jobs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise-deprecating'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Exhaustive search over specified parameter values for an estimator.\n",
       "\n",
       "Important members are fit, predict.\n",
       "\n",
       "GridSearchCV implements a \"fit\" and a \"score\" method.\n",
       "It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
       "\"transform\" and \"inverse_transform\" if they are implemented in the\n",
       "estimator used.\n",
       "\n",
       "The parameters of the estimator used to apply these methods are optimized\n",
       "by cross-validated grid-search over a parameter grid.\n",
       "\n",
       "Read more in the :ref:`User Guide <grid_search>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "estimator : estimator object.\n",
       "    This is assumed to implement the scikit-learn estimator interface.\n",
       "    Either estimator needs to provide a ``score`` function,\n",
       "    or ``scoring`` must be passed.\n",
       "\n",
       "param_grid : dict or list of dictionaries\n",
       "    Dictionary with parameters names (string) as keys and lists of\n",
       "    parameter settings to try as values, or a list of such\n",
       "    dictionaries, in which case the grids spanned by each dictionary\n",
       "    in the list are explored. This enables searching over any sequence\n",
       "    of parameter settings.\n",
       "\n",
       "scoring : string, callable, list/tuple, dict or None, default: None\n",
       "    A single string (see :ref:`scoring_parameter`) or a callable\n",
       "    (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
       "\n",
       "    For evaluating multiple metrics, either give a list of (unique) strings\n",
       "    or a dict with names as keys and callables as values.\n",
       "\n",
       "    NOTE that when using custom scorers, each scorer should return a single\n",
       "    value. Metric functions returning a list/array of values can be wrapped\n",
       "    into multiple scorers that return one value each.\n",
       "\n",
       "    See :ref:`multimetric_grid_search` for an example.\n",
       "\n",
       "    If None, the estimator's score method is used.\n",
       "\n",
       "n_jobs : int or None, optional (default=None)\n",
       "    Number of jobs to run in parallel.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "pre_dispatch : int, or string, optional\n",
       "    Controls the number of jobs that get dispatched during parallel\n",
       "    execution. Reducing this number can be useful to avoid an\n",
       "    explosion of memory consumption when more jobs get dispatched\n",
       "    than CPUs can process. This parameter can be:\n",
       "\n",
       "        - None, in which case all the jobs are immediately\n",
       "          created and spawned. Use this for lightweight and\n",
       "          fast-running jobs, to avoid delays due to on-demand\n",
       "          spawning of the jobs\n",
       "\n",
       "        - An int, giving the exact number of total jobs that are\n",
       "          spawned\n",
       "\n",
       "        - A string, giving an expression as a function of n_jobs,\n",
       "          as in '2*n_jobs'\n",
       "\n",
       "iid : boolean, default='warn'\n",
       "    If True, return the average score across folds, weighted by the number\n",
       "    of samples in each test set. In this case, the data is assumed to be\n",
       "    identically distributed across the folds, and the loss minimized is\n",
       "    the total loss per sample, and not the mean loss across the folds. If\n",
       "    False, return the average score across folds. Default is True, but\n",
       "    will change to False in version 0.22, to correspond to the standard\n",
       "    definition of cross-validation.\n",
       "\n",
       "    .. versionchanged:: 0.20\n",
       "        Parameter ``iid`` will change from True to False by default in\n",
       "        version 0.22, and will be removed in 0.24.\n",
       "\n",
       "cv : int, cross-validation generator or an iterable, optional\n",
       "    Determines the cross-validation splitting strategy.\n",
       "    Possible inputs for cv are:\n",
       "\n",
       "    - None, to use the default 3-fold cross validation,\n",
       "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
       "    - :term:`CV splitter`,\n",
       "    - An iterable yielding (train, test) splits as arrays of indices.\n",
       "\n",
       "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
       "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
       "    other cases, :class:`KFold` is used.\n",
       "\n",
       "    Refer :ref:`User Guide <cross_validation>` for the various\n",
       "    cross-validation strategies that can be used here.\n",
       "\n",
       "    .. versionchanged:: 0.20\n",
       "        ``cv`` default value if None will change from 3-fold to 5-fold\n",
       "        in v0.22.\n",
       "\n",
       "refit : boolean, string, or callable, default=True\n",
       "    Refit an estimator using the best found parameters on the whole\n",
       "    dataset.\n",
       "\n",
       "    For multiple metric evaluation, this needs to be a string denoting the\n",
       "    scorer that would be used to find the best parameters for refitting\n",
       "    the estimator at the end.\n",
       "\n",
       "    Where there are considerations other than maximum score in\n",
       "    choosing a best estimator, ``refit`` can be set to a function which\n",
       "    returns the selected ``best_index_`` given ``cv_results_``.\n",
       "\n",
       "    The refitted estimator is made available at the ``best_estimator_``\n",
       "    attribute and permits using ``predict`` directly on this\n",
       "    ``GridSearchCV`` instance.\n",
       "\n",
       "    Also for multiple metric evaluation, the attributes ``best_index_``,\n",
       "    ``best_score_`` and ``best_params_`` will only be available if\n",
       "    ``refit`` is set and all of them will be determined w.r.t this specific\n",
       "    scorer. ``best_score_`` is not returned if refit is callable.\n",
       "\n",
       "    See ``scoring`` parameter to know more about multiple metric\n",
       "    evaluation.\n",
       "\n",
       "    .. versionchanged:: 0.20\n",
       "        Support for callable added.\n",
       "\n",
       "verbose : integer\n",
       "    Controls the verbosity: the higher, the more messages.\n",
       "\n",
       "error_score : 'raise' or numeric\n",
       "    Value to assign to the score if an error occurs in estimator fitting.\n",
       "    If set to 'raise', the error is raised. If a numeric value is given,\n",
       "    FitFailedWarning is raised. This parameter does not affect the refit\n",
       "    step, which will always raise the error. Default is 'raise' but from\n",
       "    version 0.22 it will change to np.nan.\n",
       "\n",
       "return_train_score : boolean, default=False\n",
       "    If ``False``, the ``cv_results_`` attribute will not include training\n",
       "    scores.\n",
       "    Computing training scores is used to get insights on how different\n",
       "    parameter settings impact the overfitting/underfitting trade-off.\n",
       "    However computing the scores on the training set can be computationally\n",
       "    expensive and is not strictly required to select the parameters that\n",
       "    yield the best generalization performance.\n",
       "\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn import svm, datasets\n",
       ">>> from sklearn.model_selection import GridSearchCV\n",
       ">>> iris = datasets.load_iris()\n",
       ">>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
       ">>> svc = svm.SVC(gamma=\"scale\")\n",
       ">>> clf = GridSearchCV(svc, parameters, cv=5)\n",
       ">>> clf.fit(iris.data, iris.target)\n",
       "...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
       "GridSearchCV(cv=5, error_score=...,\n",
       "       estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,\n",
       "                     decision_function_shape='ovr', degree=..., gamma=...,\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=...,\n",
       "                     verbose=False),\n",
       "       iid=..., n_jobs=None,\n",
       "       param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,\n",
       "       scoring=..., verbose=...)\n",
       ">>> sorted(clf.cv_results_.keys())\n",
       "...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
       "['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
       " 'param_C', 'param_kernel', 'params',...\n",
       " 'rank_test_score', 'split0_test_score',...\n",
       " 'split2_test_score', ...\n",
       " 'std_fit_time', 'std_score_time', 'std_test_score']\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "cv_results_ : dict of numpy (masked) ndarrays\n",
       "    A dict with keys as column headers and values as columns, that can be\n",
       "    imported into a pandas ``DataFrame``.\n",
       "\n",
       "    For instance the below given table\n",
       "\n",
       "    +------------+-----------+------------+-----------------+---+---------+\n",
       "    |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
       "    +============+===========+============+=================+===+=========+\n",
       "    |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
       "    +------------+-----------+------------+-----------------+---+---------+\n",
       "    |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
       "    +------------+-----------+------------+-----------------+---+---------+\n",
       "    |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
       "    +------------+-----------+------------+-----------------+---+---------+\n",
       "    |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
       "    +------------+-----------+------------+-----------------+---+---------+\n",
       "\n",
       "    will be represented by a ``cv_results_`` dict of::\n",
       "\n",
       "        {\n",
       "        'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
       "                                     mask = [False False False False]...)\n",
       "        'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
       "                                    mask = [ True  True False False]...),\n",
       "        'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
       "                                     mask = [False False  True  True]...),\n",
       "        'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
       "        'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
       "        'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
       "        'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
       "        'rank_test_score'    : [2, 4, 3, 1],\n",
       "        'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
       "        'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
       "        'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
       "        'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
       "        'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
       "        'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
       "        'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
       "        'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
       "        'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
       "        }\n",
       "\n",
       "    NOTE\n",
       "\n",
       "    The key ``'params'`` is used to store a list of parameter\n",
       "    settings dicts for all the parameter candidates.\n",
       "\n",
       "    The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
       "    ``std_score_time`` are all in seconds.\n",
       "\n",
       "    For multi-metric evaluation, the scores for all the scorers are\n",
       "    available in the ``cv_results_`` dict at the keys ending with that\n",
       "    scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
       "    above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
       "\n",
       "best_estimator_ : estimator or dict\n",
       "    Estimator that was chosen by the search, i.e. estimator\n",
       "    which gave highest score (or smallest loss if specified)\n",
       "    on the left out data. Not available if ``refit=False``.\n",
       "\n",
       "    See ``refit`` parameter for more information on allowed values.\n",
       "\n",
       "best_score_ : float\n",
       "    Mean cross-validated score of the best_estimator\n",
       "\n",
       "    For multi-metric evaluation, this is present only if ``refit`` is\n",
       "    specified.\n",
       "\n",
       "best_params_ : dict\n",
       "    Parameter setting that gave the best results on the hold out data.\n",
       "\n",
       "    For multi-metric evaluation, this is present only if ``refit`` is\n",
       "    specified.\n",
       "\n",
       "best_index_ : int\n",
       "    The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
       "    candidate parameter setting.\n",
       "\n",
       "    The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
       "    the parameter setting for the best model, that gives the highest\n",
       "    mean score (``search.best_score_``).\n",
       "\n",
       "    For multi-metric evaluation, this is present only if ``refit`` is\n",
       "    specified.\n",
       "\n",
       "scorer_ : function or a dict\n",
       "    Scorer function used on the held out data to choose the best\n",
       "    parameters for the model.\n",
       "\n",
       "    For multi-metric evaluation, this attribute holds the validated\n",
       "    ``scoring`` dict which maps the scorer key to the scorer callable.\n",
       "\n",
       "n_splits_ : int\n",
       "    The number of cross-validation splits (folds/iterations).\n",
       "\n",
       "refit_time_ : float\n",
       "    Seconds used for refitting the best model on the whole dataset.\n",
       "\n",
       "    This is present only if ``refit`` is not False.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The parameters selected are those that maximize the score of the left out\n",
       "data, unless an explicit score is passed in which case it is used instead.\n",
       "\n",
       "If `n_jobs` was set to a value higher than one, the data is copied for each\n",
       "point in the grid (and not `n_jobs` times). This is done for efficiency\n",
       "reasons if individual jobs take very little time, but may raise errors if\n",
       "the dataset is large and not enough memory is available.  A workaround in\n",
       "this case is to set `pre_dispatch`. Then, the memory is copied only\n",
       "`pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
       "n_jobs`.\n",
       "\n",
       "See Also\n",
       "---------\n",
       ":class:`ParameterGrid`:\n",
       "    generates all the combinations of a hyperparameter grid.\n",
       "\n",
       ":func:`sklearn.model_selection.train_test_split`:\n",
       "    utility function to split the data into a development set usable\n",
       "    for fitting a GridSearchCV instance and an evaluation set for\n",
       "    its final evaluation.\n",
       "\n",
       ":func:`sklearn.metrics.make_scorer`:\n",
       "    Make a scorer from a performance metric or loss function.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\ramreddymyla\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\model_selection\\_search.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
