{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic `Regression` Binary Clasification\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem Statement:**\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has **diabetes**, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"C:\\\\Users\\\\ramreddymyla\\\\Google Drive\\\\01 DS ML DL NLP and AI With Python Lab Copy\\\\02 Lab Data\\\\Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ramreddymyla\\\\Google Drive\\\\01 DS ML DL NLP and AI With Python Lab Copy\\\\02 Lab Data\\\\Python'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"pima-indians-diabetes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "pregnancies    768 non-null int64\n",
      "glucose        768 non-null int64\n",
      "diastolic      768 non-null int64\n",
      "triceps        768 non-null int64\n",
      "insulin        768 non-null int64\n",
      "bmi            768 non-null float64\n",
      "dpf            768 non-null float64\n",
      "age            768 non-null int64\n",
      "diabetes       768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"pregnancies\",\"glucose\",\"diastolic\",\"triceps\",\"insulin\",\"bmi\",\"dpf\",\"age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 8 columns):\n",
      "pregnancies    768 non-null int64\n",
      "glucose        768 non-null int64\n",
      "diastolic      768 non-null int64\n",
      "triceps        768 non-null int64\n",
      "insulin        768 non-null int64\n",
      "bmi            768 non-null float64\n",
      "dpf            768 non-null float64\n",
      "age            768 non-null int64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 48.1 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"diabetes\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreturn_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Find the unique elements of an array.\n",
       "\n",
       "Returns the sorted unique elements of an array. There are three optional\n",
       "outputs in addition to the unique elements:\n",
       "\n",
       "* the indices of the input array that give the unique values\n",
       "* the indices of the unique array that reconstruct the input array\n",
       "* the number of times each unique value comes up in the input array\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "ar : array_like\n",
       "    Input array. Unless `axis` is specified, this will be flattened if it\n",
       "    is not already 1-D.\n",
       "return_index : bool, optional\n",
       "    If True, also return the indices of `ar` (along the specified axis,\n",
       "    if provided, or in the flattened array) that result in the unique array.\n",
       "return_inverse : bool, optional\n",
       "    If True, also return the indices of the unique array (for the specified\n",
       "    axis, if provided) that can be used to reconstruct `ar`.\n",
       "return_counts : bool, optional\n",
       "    If True, also return the number of times each unique item appears\n",
       "    in `ar`.\n",
       "\n",
       "    .. versionadded:: 1.9.0\n",
       "\n",
       "axis : int or None, optional\n",
       "    The axis to operate on. If None, `ar` will be flattened. If an integer,\n",
       "    the subarrays indexed by the given axis will be flattened and treated\n",
       "    as the elements of a 1-D array with the dimension of the given axis,\n",
       "    see the notes for more details.  Object arrays or structured arrays\n",
       "    that contain objects are not supported if the `axis` kwarg is used. The\n",
       "    default is None.\n",
       "\n",
       "    .. versionadded:: 1.13.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "unique : ndarray\n",
       "    The sorted unique values.\n",
       "unique_indices : ndarray, optional\n",
       "    The indices of the first occurrences of the unique values in the\n",
       "    original array. Only provided if `return_index` is True.\n",
       "unique_inverse : ndarray, optional\n",
       "    The indices to reconstruct the original array from the\n",
       "    unique array. Only provided if `return_inverse` is True.\n",
       "unique_counts : ndarray, optional\n",
       "    The number of times each of the unique values comes up in the\n",
       "    original array. Only provided if `return_counts` is True.\n",
       "\n",
       "    .. versionadded:: 1.9.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "numpy.lib.arraysetops : Module with a number of other functions for\n",
       "                        performing set operations on arrays.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "When an axis is specified the subarrays indexed by the axis are sorted.\n",
       "This is done by making the specified axis the first dimension of the array\n",
       "and then flattening the subarrays in C order. The flattened subarrays are\n",
       "then viewed as a structured type with each element given a label, with the\n",
       "effect that we end up with a 1-D array of structured types that can be\n",
       "treated in the same way as any other 1-D array. The result is that the\n",
       "flattened subarrays are sorted in lexicographic order starting with the\n",
       "first element.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> np.unique([1, 1, 2, 2, 3, 3])\n",
       "array([1, 2, 3])\n",
       ">>> a = np.array([[1, 1], [2, 3]])\n",
       ">>> np.unique(a)\n",
       "array([1, 2, 3])\n",
       "\n",
       "Return the unique rows of a 2D array\n",
       "\n",
       ">>> a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\n",
       ">>> np.unique(a, axis=0)\n",
       "array([[1, 0, 0], [2, 3, 4]])\n",
       "\n",
       "Return the indices of the original array that give the unique values:\n",
       "\n",
       ">>> a = np.array(['a', 'b', 'b', 'c', 'a'])\n",
       ">>> u, indices = np.unique(a, return_index=True)\n",
       ">>> u\n",
       "array(['a', 'b', 'c'],\n",
       "       dtype='|S1')\n",
       ">>> indices\n",
       "array([0, 1, 3])\n",
       ">>> a[indices]\n",
       "array(['a', 'b', 'c'],\n",
       "       dtype='|S1')\n",
       "\n",
       "Reconstruct the input array from the unique values:\n",
       "\n",
       ">>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
       ">>> u, indices = np.unique(a, return_inverse=True)\n",
       ">>> u\n",
       "array([1, 2, 3, 4, 6])\n",
       ">>> indices\n",
       "array([0, 1, 4, 3, 1, 2, 1])\n",
       ">>> u[indices]\n",
       "array([1, 2, 6, 4, 2, 3, 2])\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\ramreddymyla\\anaconda3\\envs\\dl\\lib\\site-packages\\numpy\\lib\\arraysetops.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([500, 268], dtype=int64))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split into Train Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                   random_state=42 # seed \n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460.79999999999995"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768* 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249    0\n",
       "22     1\n",
       "221    1\n",
       "526    0\n",
       "751    0\n",
       "752    0\n",
       "424    1\n",
       "644    0\n",
       "203    0\n",
       "500    0\n",
       "93     1\n",
       "369    1\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.143</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.805</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.299</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.516</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>152</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.730</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.235</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>90</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.313</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.277</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>102</td>\n",
       "      <td>28</td>\n",
       "      <td>140</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.234</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age\n",
       "249            1      111         86       19        0  30.1  0.143   23\n",
       "22             7      196         90        0        0  39.8  0.451   41\n",
       "221            2      158         90        0        0  31.6  0.805   66\n",
       "526            1       97         64       19       82  18.2  0.299   21\n",
       "751            1      121         78       39       74  39.0  0.261   28\n",
       "752            3      108         62       24        0  26.0  0.223   25\n",
       "424            8      151         78       32      210  42.9  0.516   36\n",
       "644            3      103         72       30      152  27.6  0.730   27\n",
       "203            2       99         70       16       44  20.4  0.235   27\n",
       "500            2      117         90       19       71  25.2  0.313   21\n",
       "93             4      134         72        0        0  23.8  0.277   60\n",
       "369            1      133        102       28      140  32.8  0.234   45"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramreddymyla\\Anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624    0\n",
       "690    0\n",
       "473    0\n",
       "204    0\n",
       "97     0\n",
       "336    0\n",
       "568    0\n",
       "148    0\n",
       "667    1\n",
       "212    0\n",
       "199    1\n",
       "265    0\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[2:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Confusion Matrix\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Right answers\n",
    "1. How many members really not suffering with diabetes and machine also labeling as no diabetes ?? 174\n",
    "2. How many members really suffering with diabetes and machine also labeling as diabetes ?? 66\n",
    "\n",
    "* Wrong answers\n",
    "1. How many members really suffering with diabetes and machine labeling as no diabetes ?? 32\n",
    "2. How many members really not suffering with diabetes and machine labeling as diabetes ?? 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[174,  32],\n",
       "       [ 36,  66]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "174+32+36+66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Real values and machine values are on same page then T else F\n",
    "- P or N is decided based on Real Values(Ground Truth)\n",
    "\n",
    "![image](https://github.com/rritec/datahexa/blob/dev/images/ds000003.png?raw=true)\n",
    "\n",
    "[Read about confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Classification Report\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Precision:` When it predicts yes, how often is it correct? When it predicts No, how often is it correct? \n",
    "\n",
    "    - Precision = TP/(FP+TP)(a.k.a actual yes) = 66/98=0.67\n",
    "    - Precision = TN/(TN+FN) (a.k.a actual NO)    = 174/210=0.828\n",
    "    \n",
    "- `True Positive Rate/Sensitivity/Recall`: When it's actually yes, how often does it predict yes? or When it's actually no, how often does it predict no?\n",
    "\n",
    "    - TP/(TP+FN)(aka predicted yes) = 66/(36+66)=0.647\n",
    "    - TN/(TN+FP)(aka predicted No) = 174/(174+32)=0.84\n",
    "    \n",
    "- `F Score:` This is a weighted average of the true positive rate (recall) and precision\t\n",
    "\n",
    "    - $F1_{score} = \\frac {(2 * precision * recall)}{(precision + recall)}$  \n",
    "    \n",
    "- `Support:` \n",
    "    - Actual No label patients count =174 + 32 = 206\n",
    "    - Actual Yes label patients count =36+66 = 102\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       206\n",
      "           1       0.67      0.65      0.66       102\n",
      "\n",
      "    accuracy                           0.78       308\n",
      "   macro avg       0.75      0.75      0.75       308\n",
      "weighted avg       0.78      0.78      0.78       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Receiver Operating Characteristic(ROC) Curve\n",
    "- The ROC curve is created by plotting the true positive rate (TPR)/sensitivity against the false positive rate (FPR) at various threshold settings\n",
    "- In machine learning The true-positive rate is also known as sensitivity, recall or probability of detection Linear regression\n",
    "- The false-positive rate is also known as the fall-out or probability of `False` alarm\n",
    "\n",
    "[Read about ROC Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdrop_intermediate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Compute Receiver operating characteristic (ROC)\n",
       "\n",
       "Note: this implementation is restricted to the binary classification task.\n",
       "\n",
       "Read more in the :ref:`User Guide <roc_metrics>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "\n",
       "y_true : array, shape = [n_samples]\n",
       "    True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n",
       "    pos_label should be explicitly given.\n",
       "\n",
       "y_score : array, shape = [n_samples]\n",
       "    Target scores, can either be probability estimates of the positive\n",
       "    class, confidence values, or non-thresholded measure of decisions\n",
       "    (as returned by \"decision_function\" on some classifiers).\n",
       "\n",
       "pos_label : int or str, default=None\n",
       "    The label of the positive class.\n",
       "    When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},\n",
       "    ``pos_label`` is set to 1, otherwise an error will be raised.\n",
       "\n",
       "sample_weight : array-like of shape = [n_samples], optional\n",
       "    Sample weights.\n",
       "\n",
       "drop_intermediate : boolean, optional (default=True)\n",
       "    Whether to drop some suboptimal thresholds which would not appear\n",
       "    on a plotted ROC curve. This is useful in order to create lighter\n",
       "    ROC curves.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       parameter *drop_intermediate*.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "fpr : array, shape = [>2]\n",
       "    Increasing false positive rates such that element i is the false\n",
       "    positive rate of predictions with score >= thresholds[i].\n",
       "\n",
       "tpr : array, shape = [>2]\n",
       "    Increasing true positive rates such that element i is the true\n",
       "    positive rate of predictions with score >= thresholds[i].\n",
       "\n",
       "thresholds : array, shape = [n_thresholds]\n",
       "    Decreasing thresholds on the decision function used to compute\n",
       "    fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
       "    and is arbitrarily set to `max(y_score) + 1`.\n",
       "\n",
       "See also\n",
       "--------\n",
       "roc_auc_score : Compute the area under the ROC curve\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Since the thresholds are sorted from low to high values, they\n",
       "are reversed upon returning them to ensure they correspond to both ``fpr``\n",
       "and ``tpr``, which are sorted in reversed order during their calculation.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] `Wikipedia entry for the Receiver operating characteristic\n",
       "        <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
       "\n",
       ".. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\n",
       "       Letters, 2006, 27(8):861-874.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn import metrics\n",
       ">>> y = np.array([1, 1, 2, 2])\n",
       ">>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
       ">>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
       ">>> fpr\n",
       "array([0. , 0. , 0.5, 0.5, 1. ])\n",
       ">>> tpr\n",
       "array([0. , 0.5, 0.5, 1. , 1. ])\n",
       ">>> thresholds\n",
       "array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\ramreddymyla\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\ranking.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66635194, 0.33364806],\n",
       "       [0.26491663, 0.73508337],\n",
       "       [0.5133914 , 0.4866086 ],\n",
       "       [0.67306851, 0.32693149],\n",
       "       [0.85095436, 0.14904564]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict_proba(X_test)[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities of positive class: y_pred_prob\n",
    "y_pred_prob = log.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33364806, 0.73508337, 0.4866086 , 0.32693149, 0.14904564])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC computation\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_fpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
       "from prediction scores.\n",
       "\n",
       "Note: this implementation is restricted to the binary classification task\n",
       "or multilabel classification task in label indicator format.\n",
       "\n",
       "Read more in the :ref:`User Guide <roc_metrics>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : array, shape = [n_samples] or [n_samples, n_classes]\n",
       "    True binary labels or binary label indicators.\n",
       "\n",
       "y_score : array, shape = [n_samples] or [n_samples, n_classes]\n",
       "    Target scores, can either be probability estimates of the positive\n",
       "    class, confidence values, or non-thresholded measure of decisions\n",
       "    (as returned by \"decision_function\" on some classifiers). For binary\n",
       "    y_true, y_score is supposed to be the score of the class with greater\n",
       "    label.\n",
       "\n",
       "average : string, [None, 'micro', 'macro' (default), 'samples', 'weighted']\n",
       "    If ``None``, the scores for each class are returned. Otherwise,\n",
       "    this determines the type of averaging performed on the data:\n",
       "\n",
       "    ``'micro'``:\n",
       "        Calculate metrics globally by considering each element of the label\n",
       "        indicator matrix as a label.\n",
       "    ``'macro'``:\n",
       "        Calculate metrics for each label, and find their unweighted\n",
       "        mean.  This does not take label imbalance into account.\n",
       "    ``'weighted'``:\n",
       "        Calculate metrics for each label, and find their average, weighted\n",
       "        by support (the number of true instances for each label).\n",
       "    ``'samples'``:\n",
       "        Calculate metrics for each instance, and find their average.\n",
       "\n",
       "    Will be ignored when ``y_true`` is binary.\n",
       "\n",
       "sample_weight : array-like of shape = [n_samples], optional\n",
       "    Sample weights.\n",
       "\n",
       "max_fpr : float > 0 and <= 1, optional\n",
       "    If not ``None``, the standardized partial AUC [3]_ over the range\n",
       "    [0, max_fpr] is returned.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "auc : float\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] `Wikipedia entry for the Receiver operating characteristic\n",
       "        <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
       "\n",
       ".. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\n",
       "       Letters, 2006, 27(8):861-874.\n",
       "\n",
       ".. [3] `Analyzing a portion of the ROC curve. McClish, 1989\n",
       "        <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n",
       "\n",
       "See also\n",
       "--------\n",
       "average_precision_score : Area under the precision-recall curve\n",
       "\n",
       "roc_curve : Compute Receiver operating characteristic (ROC) curve\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.metrics import roc_auc_score\n",
       ">>> y_true = np.array([0, 0, 1, 1])\n",
       ">>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
       ">>> roc_auc_score(y_true, y_scores)\n",
       "0.75\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\ramreddymyla\\anaconda3\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\ranking.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61760456, 0.38239544],\n",
       "       [0.77666437, 0.22333563],\n",
       "       [0.78202778, 0.21797222],\n",
       "       [0.75147717, 0.24852283],\n",
       "       [0.54380739, 0.45619261]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict_proba(X_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities: y_pred_prob # related yes label # 1 label\n",
    "y_pred_prob = log.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-09e72c498d36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_prob' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8268608414239483\n"
     ]
    }
   ],
   "source": [
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores computed using 5-fold cross-validation: [0.7987037  0.80759259 0.81944444 0.86622642 0.85056604]\n"
     ]
    }
   ],
   "source": [
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(log, X, y, cv=5, scoring='roc_auc')\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e-05, 8.48343e-05, 7.19686e-04, 6.10540e-03, 5.17947e-02,\n",
       "       4.39397e-01, 3.72759e+00, 3.16228e+01, 2.68270e+02, 2.27585e+03,\n",
       "       1.93070e+04, 1.63789e+05, 1.38950e+06, 1.17877e+07, 1.00000e+08])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 163789.3706954068}\n",
      "Best score is 0.7721354166666666\n"
     ]
    }
   ],
   "source": [
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Home Work:** \n",
    "- [With one more dataset](https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8)\n",
    "\n",
    "- [write own code for logistic regression](https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after doing above home work,you need to answer\n",
    "## Balanced Vs Unbalanced Data\n",
    "### How to convert unbalanced data into balanced\n",
    "#### oversampling\n",
    "#### Under Sampling\n",
    "##### smote"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
